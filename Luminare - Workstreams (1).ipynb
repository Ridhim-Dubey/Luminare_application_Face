{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bffe7e4c",
   "metadata": {},
   "source": [
    "# Workstreams\n",
    "\n",
    "1. Web App Development\n",
    "\n",
    "2. Generate additional test images (via DALL E 3 or StyleGAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfa7202",
   "metadata": {},
   "source": [
    "## Web Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e336f1b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'flask'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflask\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Flask, request, jsonify\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'flask'"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228b0210",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea10c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/')\n",
    "def index():\n",
    "    return 'Welcome to the Luminare API'\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    data = request.json \n",
    "    model_input = data['input']\n",
    "    \n",
    "    # Make a request to AWS Lambda API\n",
    "    api_url = 'AWS_API_GATEWAY_URL'\n",
    "    response = requests.post(api_url, json={'input': model_input})\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        return jsonify({'result': result})\n",
    "    \n",
    "    else:\n",
    "        return jsonify({'error': 'Failed to get prediction'})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70fe4a2",
   "metadata": {},
   "source": [
    "## Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d50be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import requests\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54fea91",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = ''\n",
    "\n",
    "# Generate synthetic images using DALL-E 3\n",
    "def generate_images(prompt, num_images=100):\n",
    "    response = openai.Image.create(\n",
    "        model=\"image-alpha-001\",\n",
    "        prompt=prompt,\n",
    "        n=num_images,\n",
    "        size=\"256x256\",\n",
    "    )\n",
    "\n",
    "    image_urls = [item['url'] for item in response['data']]\n",
    "    return image_urls\n",
    "\n",
    "# Download and save images\n",
    "def download_images(image_urls, folder, label):\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    for i, url in enumerate(image_urls):\n",
    "        img_data = requests.get(url).content\n",
    "        with open(f'{folder}/{label}_{i}.png', 'wb') as handler:\n",
    "            handler.write(img_data)\n",
    "\n",
    "# Generate synthetic images labeled as \"fake\"\n",
    "fake_prompt = \"A collection of fake images\"\n",
    "fake_images = generate_images(fake_prompt)\n",
    "download_images(fake_images, 'dataset', 'fake')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adfa64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEXT STEP: Download real images\n",
    "# real_images = download_real_images()\n",
    "# download_images(real_images, 'dataset', 'real')\n",
    "\n",
    "# Create labels\n",
    "fake_labels = ['fake'] * len(fake_images)\n",
    "# real_labels = ['real'] * len(real_images)\n",
    "\n",
    "# Combine synthetic and real images and labels\n",
    "# all_images = fake_images + real_images\n",
    "all_labels = fake_labels  # + real_labels\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    np.array(fake_images), np.array(fake_labels), test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ca2ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a logistic regression model for evaluation\n",
    "# Can replace this with Saket or Cheick's pre-existing models\n",
    "def preprocess_images(image_paths):\n",
    "    images = [Image.open(path).convert(\"RGB\").resize((64, 64)) for path in image_paths]\n",
    "    return np.array([np.array(img) for img in images])\n",
    "\n",
    "X_train_processed = preprocess_images(X_train)\n",
    "X_test_processed = preprocess_images(X_test)\n",
    "\n",
    "# Flatten the images for logistic regression\n",
    "X_train_flat = X_train_processed.reshape(X_train_processed.shape[0], -1)\n",
    "X_test_flat = X_test_processed.reshape(X_test_processed.shape[0], -1)\n",
    "\n",
    "# Convert labels to numerical values\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_test_encoded = le.transform(y_test)\n",
    "\n",
    "# Train a logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_flat, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e59bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_flat)\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_encoded, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
